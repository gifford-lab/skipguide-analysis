{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dat-B: Characterize Skipping\n",
    "dat-B in this study refers to the set of repair genotypes observed in Spliced (Pre and PostCas9, where PreCas9 is control, and gives us wildtype $\\Psi$), and their count of transcripts with or without Exon B. The code here extracts these information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "from utils import *\n",
    "\n",
    "import sys\n",
    "import regex\n",
    "import copy\n",
    "import numpy as np\n",
    "import collections\n",
    "import multiprocessing\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "# Suppress pandas future warning, which messes tqdm\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_spliced_precas_map = load_bc_seq(BC_SPLICED_PRECAS_MAP)\n",
    "bc_spliced1_postcas_map = load_bc_seq(BC_SPLICED1_POSTCAS_MAP)\n",
    "bc_spliced2_postcas_map = load_bc_seq(BC_SPLICED2_POSTCAS_MAP)\n",
    "\n",
    "bc_tid_indel_postcas_map = load_bc_id_indel(BC_TID_INDEL_POSTCAS_MAP)\n",
    "unnorm_gt_indel_dist_map = load_var(UNNORM_GT_INDEL_DIST_MAP)\n",
    "gt_indel_dist_map = load_var(GT_INDEL_DIST_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "design_t_kmers_map = {design_t:kmers(design_t, K) for design_t in exp_target_tid_map}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterize Skipping\n",
    "For a given spliced RNA transcript sequence, we need to figure out the original designed target (splice-acceptor) sequence. Similar to what we did in the construction of dat-A, for a query sequence Q, we find the most similar designed sequence D from lib-SA by computing the Dice Coefficient between Q and D, using 5-mers, and picking the D that is most similar to Q.\n",
    "\n",
    "For a transcript with Exon B skipped, only the barcode information is known. To associate it with its repair genotype, its barcode is queried on the dat-A PostCas lookup table (variable bc_tid_indel_postcas_map) to find the repair genotype with the same barcode. If there are multiple repair genotypes with the same barcode, then the one with the largest read count is chosen for association. If the barcode is not observed in dat-A, then the transcript is discarded.\n",
    "\n",
    "For a transcript with Exon B retained, naturally only the Exon B portion of the repair outcome is discernible. Similarly to identify its repair genotype, its barcode is queried on dat-A lookup table. If there is one repair genotype with the same barcode and that repair genotype agrees with the partial Exon B we observe in the transcript, then we're set. If there are multiple repair genotypes with the same barcode AND agrees with the partial Exon B we observe in the transcript, then one of them is picked randomly, sampled according to the frequency of observing each candidate (see code). How can there be multiple possible repair genotypes? Consider the following original and spliced sequences:\n",
    "\n",
    "```\n",
    "Original ('|' denote intron-exon boundary)\n",
    "AGTCAAG|CGGTCA\n",
    "\n",
    "Repair outcomes\n",
    "AGTC---|CGGTCA\n",
    "AGTCAA-|CGGTCA\n",
    "AGTCA--|CGGTCA\n",
    "AGTCA--|--GTCA\n",
    "\n",
    "Observed transcript:\n",
    "ExonA|CGGTCA\n",
    "```\n",
    "\n",
    "We see that the first three repair outcomes all can give rise to the observed transcript, and there's no way of knowing which one it is if all three happen to match to the same barcode (rare, but possible)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characterize PreCas Spliced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_splice(ref, obs):\n",
    "    prog = regex.compile(r'(?b)('+obs+'){e<=3}')\n",
    "    return prog.search(ref)\n",
    "\n",
    "\n",
    "def get_spliceidx(ref, obs):\n",
    "    m = search_splice(ref, obs)\n",
    "    if m:\n",
    "        return m.start()\n",
    "    return -1\n",
    "\n",
    "\n",
    "def get_tid_spliced(obs_t):\n",
    "    if len(obs_t) < 5:\n",
    "        return None\n",
    "    \n",
    "    if len(obs_t) > 12 and hamming_distance('CACAACATCGAG', obs_t[0:12]) <= 2:\n",
    "        obs_t = obs_t[12:]\n",
    "    \n",
    "    max_sim = -float('inf')\n",
    "    best_design_t = None\n",
    "    for design_t in exp_target_tid_map:\n",
    "        if design_t in obs_t or obs_t in design_t:\n",
    "            max_sim = 1\n",
    "            best_design_t = design_t\n",
    "            break\n",
    "        \n",
    "        sim = dice_coefficient(obs_t, design_t_kmers_map[design_t], K)\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "            best_design_t = design_t\n",
    "    \n",
    "    return best_design_t, obs_t, max_sim\n",
    "\n",
    "\n",
    "def get_tid_spliceidx_precas(obs_t):      \n",
    "    t_spliced = get_tid_spliced(obs_t)\n",
    "    if t_spliced is None:\n",
    "        return None, -1\n",
    "    \n",
    "    best_design_t, obs_t, max_sim = t_spliced\n",
    "    \n",
    "    if max_sim < 0.3:\n",
    "        return None, -1\n",
    "    \n",
    "    spliceidx = get_spliceidx(best_design_t, obs_t)\n",
    "    return exp_target_tid_map[best_design_t], spliceidx\n",
    "\n",
    "\n",
    "def generate_bc_tid_spliceidx_precas_map(bc_precas_splice_map):\n",
    "    try:\n",
    "        p = multiprocessing.Pool(NUM_PROCESSES)\n",
    "\n",
    "        bc_tid_spliceidx_map = collections.defaultdict(lambda: collections.defaultdict(lambda: collections.defaultdict(int)))\n",
    "\n",
    "        obs_ts = list({obs_t for bc in tqdm(bc_precas_splice_map) for obs_t in bc_precas_splice_map[bc]})\n",
    "        tid_spliceidxs = []\n",
    "        for tid_spliceidx in tqdm(p.imap(get_tid_spliceidx_precas, obs_ts, chunksize=1), total=len(obs_ts)):\n",
    "            tid_spliceidxs.append(tid_spliceidx)\n",
    "\n",
    "        obs_tidspliceidx_map = {obs_t:tid_spliceidxs[i] for i, obs_t in enumerate(obs_ts)}\n",
    "\n",
    "        for bc in tqdm(bc_precas_splice_map):\n",
    "            for obs_t in bc_precas_splice_map[bc]:\n",
    "                if obs_t == 'SKIPPED':\n",
    "                    tid, spliceidx = 'SKIPPED', -1\n",
    "                else:\n",
    "                    tid, spliceidx = obs_tidspliceidx_map[obs_t]\n",
    "                    if tid is None or spliceidx == -1:\n",
    "                        continue\n",
    "                    \n",
    "                bc_tid_spliceidx_map[bc][tid][spliceidx] += bc_precas_splice_map[bc][obs_t]\n",
    "\n",
    "        print(\"(Before) Num Unique BCs:\", len(bc_precas_splice_map))\n",
    "        print(\"(After) Num Unique BCs:\", len(bc_tid_spliceidx_map))\n",
    "    finally:\n",
    "        p.close()\n",
    "        p.join()\n",
    "\n",
    "    return bc_tid_spliceidx_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pickle_exists(BC_TID_SPLICEIDX_PRECAS_MAP):\n",
    "    bc_tid_spliceidx_precas_map = generate_bc_tid_spliceidx_precas_map(bc_spliced_precas_map)\n",
    "    save_bc_id_indel(bc_tid_spliceidx_precas_map, BC_TID_SPLICEIDX_PRECAS_MAP)\n",
    "else:\n",
    "    bc_tid_spliceidx_precas_map = load_bc_id_indel(BC_TID_SPLICEIDX_PRECAS_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characterize PostCas Spliced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gid_from_indel(indel, tid):\n",
    "    if indel[1] in DELETION_SIGNATURES:\n",
    "        _, _, deletion_size, genotype_pos, cutsite = indel\n",
    "        for gid in exp_tid_gids_map[tid]:\n",
    "            design_t = exp_tid_target_map[tid]\n",
    "            grna = exp_gid_grna_map[gid]\n",
    "            g_orientation = exp_grna_gid_map[grna][1]\n",
    "            if cutsite == get_cutsite(grna, design_t, g_orientation):\n",
    "                return gid\n",
    "    elif indel[1] in INSERTION_SIGNATURES and indel[2] == 1:\n",
    "        _, _, _, inserted_base, cutsite =  indel\n",
    "        for gid in exp_tid_gids_map[tid]:\n",
    "            design_t = exp_tid_target_map[tid]\n",
    "            grna = exp_gid_grna_map[gid]\n",
    "            g_orientation = exp_grna_gid_map[grna][1]\n",
    "            if cutsite == get_cutsite(grna, design_t, g_orientation):\n",
    "                return gid\n",
    "    return None\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "def get_indel_spliceidx(a):\n",
    "    t_spliced, bc = a\n",
    "    if t_spliced is None:\n",
    "        return None\n",
    "    \n",
    "    best_design_t, obs_t, max_sim = t_spliced\n",
    "    tid = exp_target_tid_map[best_design_t]\n",
    "    \n",
    "    if tid not in bc_tid_indel_postcas_map[bc]:\n",
    "        return None\n",
    "    \n",
    "    m_wt = search_splice(best_design_t, obs_t)\n",
    "    \n",
    "    min_fuzzy_count = float('inf')\n",
    "    best_indel_spliceidx = []\n",
    "    for indel in bc_tid_indel_postcas_map[bc][tid]:\n",
    "        if indel[1] in DELETION_SIGNATURES or (indel[1] in INSERTION_SIGNATURES and indel[2] == 1):\n",
    "            prod = get_simulated_product(indel, best_design_t)\n",
    "            m = search_splice(prod, obs_t)\n",
    "            if m:\n",
    "                fuzzy_count = sum(m.fuzzy_counts)\n",
    "                if fuzzy_count == min_fuzzy_count:\n",
    "                    best_indel_spliceidx.append((m.start(), indel, tid))\n",
    "                elif fuzzy_count < min_fuzzy_count:\n",
    "                    min_fuzzy_count = fuzzy_count\n",
    "                    best_indel_spliceidx = [(m.start(), indel, tid)]\n",
    "\n",
    "    # Unsure: Could be uncut WT, or indel only in the intron.\n",
    "    # There's no way of knowing which, so just ignore them\n",
    "    if m_wt and sum(m_wt.fuzzy_counts) < min_fuzzy_count:\n",
    "        return None\n",
    "\n",
    "    if len(best_indel_spliceidx) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Unique best match found\n",
    "    if len(best_indel_spliceidx) == 1:\n",
    "        return best_indel_spliceidx[0]\n",
    "    \n",
    "    # If reached here, there are multiple possible original repair genotypes\n",
    "    # Rather than giving up here and discarding them,\n",
    "    # we look at the observed frequencies for each of the possible repair genotypes in question\n",
    "    # This information is available from dat-A. We then sample one of these repair genotypes\n",
    "    # according to these frequencies, and choose that as the original repair genotype.\n",
    "    p = []\n",
    "    for (s, indel, tid) in best_indel_spliceidx:\n",
    "        gid = get_gid_from_indel(indel, tid)\n",
    "        grna_seq = exp_gid_grna_map[gid]\n",
    "        grna_orientation = exp_grna_gid_map[grna_seq][1]\n",
    "        \n",
    "        dist = gt_indel_dist_map[(grna_seq, best_design_t, grna_orientation)]\n",
    "        \n",
    "        if indel[1] in DELETION_SIGNATURES:\n",
    "            _, _, deletion_size, genotype_pos, cutsite = indel\n",
    "            p.append(dist[-deletion_size][genotype_pos])\n",
    "        elif indel[1] in INSERTION_SIGNATURES:\n",
    "            _, _, _, inserted_base, cutsite = indel\n",
    "            p.append(dist[1][inserted_base])\n",
    "    p = np.array(p) / np.sum(p)\n",
    "    return best_indel_spliceidx[np.random.choice(len(best_indel_spliceidx), 1, p=p)[0]]  \n",
    "    \n",
    "\n",
    "def generate_bc_tid_spliceidx_postcas_map(bc_postcas_splice_map):\n",
    "    try:\n",
    "        p = multiprocessing.Pool(NUM_PROCESSES)\n",
    "\n",
    "        bc_tid_spliceidx_map = collections.defaultdict(lambda: collections.defaultdict(lambda: collections.defaultdict(int)))\n",
    "\n",
    "        obs_ts = list({obs_t for bc in tqdm(bc_postcas_splice_map) for obs_t in bc_postcas_splice_map[bc]})\n",
    "        t_splices = []\n",
    "        for t_spliced in tqdm(p.imap(get_tid_spliced, obs_ts, chunksize=1), total=len(obs_ts)):\n",
    "            t_splices.append(t_spliced)\n",
    "        \n",
    "        obs_tspliced_map = {obs_t:t_splices[i] for i, obs_t in enumerate(obs_ts)}\n",
    "        \n",
    "        tsplice_bcs = set()\n",
    "        for bc in tqdm(bc_postcas_splice_map):\n",
    "            if bc in bc_tid_indel_postcas_map:\n",
    "                for obs_t in bc_postcas_splice_map[bc]:\n",
    "                    tsplice_bcs.add((obs_tspliced_map[obs_t], bc))\n",
    "        tsplice_bcs = list(tsplice_bcs)\n",
    "        \n",
    "        indel_spliceidxs = []\n",
    "        for indel_spliceidx in tqdm(p.imap(get_indel_spliceidx, tsplice_bcs, chunksize=1), total=len(tsplice_bcs)):\n",
    "            indel_spliceidxs.append(indel_spliceidx)\n",
    "            \n",
    "        tsplicebc_spliceidx_map = {tsplicebc:indel_spliceidxs[i] for i, tsplicebc in enumerate(tsplice_bcs)}\n",
    "        \n",
    "        for bc in tqdm(bc_postcas_splice_map):\n",
    "            if bc in bc_tid_indel_postcas_map:\n",
    "                for obs_t in bc_postcas_splice_map[bc]:\n",
    "                    if obs_t == 'SKIPPED':\n",
    "                        bc_tid_spliceidx_map[bc]['SKIPPED'][-1] += bc_postcas_splice_map[bc][obs_t]\n",
    "                        continue\n",
    "                        \n",
    "                    spliceidx_indel_tid = tsplicebc_spliceidx_map[(obs_tspliced_map[obs_t], bc)]\n",
    "                    if spliceidx_indel_tid:\n",
    "                        spliceidx, indel, tid = spliceidx_indel_tid\n",
    "                        bc_tid_spliceidx_map[bc][tid][(spliceidx, indel)] += bc_postcas_splice_map[bc][obs_t]\n",
    "\n",
    "        print(\"(Before) Num Unique BCs:\", len(bc_postcas_splice_map))\n",
    "        print(\"(After) Num Unique BCs:\", len(bc_tid_spliceidx_map))\n",
    "    finally:\n",
    "        p.close()\n",
    "        p.join()\n",
    "\n",
    "    return bc_tid_spliceidx_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pickle_exists(BC_TID_SPLICEIDX_POSTCAS_MAP):\n",
    "    bc_tid1_spliceidx_postcas_map = generate_bc_tid_spliceidx_postcas_map(bc_spliced1_postcas_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pickle_exists(BC_TID_SPLICEIDX_POSTCAS_MAP):\n",
    "    bc_tid2_spliceidx_postcas_map = generate_bc_tid_spliceidx_postcas_map(bc_spliced2_postcas_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_bc_tid_spliceidx_maps(bc_tid1_spliceidx_map, bc_tid2_spliceidx_map):\n",
    "    bc_tid_spliceidx_map = collections.defaultdict(lambda: collections.defaultdict(lambda: collections.defaultdict(int)))\n",
    "    \n",
    "    merged = 0\n",
    "    for bc in tqdm(bc_tid1_spliceidx_map.keys() & bc_tid2_spliceidx_map.keys()):\n",
    "        for tid in (bc_tid1_spliceidx_map[bc].keys() & bc_tid2_spliceidx_map[bc].keys()):\n",
    "            for spliceidx in (bc_tid1_spliceidx_map[bc][tid].keys() & bc_tid2_spliceidx_map[bc][tid].keys()):\n",
    "                bc_tid_spliceidx_map[bc][tid][spliceidx] += np.mean([bc_tid1_spliceidx_map[bc][tid][spliceidx], bc_tid2_spliceidx_map[bc][tid][spliceidx]])\n",
    "                merged += 1\n",
    "    \n",
    "    for bc in tqdm(bc_tid1_spliceidx_map):\n",
    "        for tid in bc_tid1_spliceidx_map[bc]:\n",
    "            for spliceidx in bc_tid1_spliceidx_map[bc][tid]:\n",
    "                if not (bc in bc_tid_spliceidx_map and tid in bc_tid_spliceidx_map[bc] and spliceidx in bc_tid_spliceidx_map[bc][tid]):\n",
    "                    bc_tid_spliceidx_map[bc][tid][spliceidx] += bc_tid1_spliceidx_map[bc][tid][spliceidx]\n",
    "    for bc in tqdm(bc_tid2_spliceidx_map):\n",
    "        for tid in bc_tid2_spliceidx_map[bc]:\n",
    "            for spliceidx in bc_tid2_spliceidx_map[bc][tid]:\n",
    "                if not (bc in bc_tid_spliceidx_map and tid in bc_tid_spliceidx_map[bc] and spliceidx in bc_tid_spliceidx_map[bc][tid]):\n",
    "                    bc_tid_spliceidx_map[bc][tid][spliceidx] += bc_tid2_spliceidx_map[bc][tid][spliceidx]\n",
    "    \n",
    "    print(\"Num Common:\", merged)\n",
    "    return bc_tid_spliceidx_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pickle_exists(BC_TID_SPLICEIDX_POSTCAS_MAP):\n",
    "    bc_tid_spliceidx_postcas_map = merge_bc_tid_spliceidx_maps(bc_tid1_spliceidx_postcas_map, bc_tid2_spliceidx_postcas_map)\n",
    "    save_bc_id_indel(bc_tid_spliceidx_postcas_map, BC_TID_SPLICEIDX_POSTCAS_MAP)\n",
    "else:\n",
    "    bc_tid_spliceidx_postcas_map = load_bc_id_indel(BC_TID_SPLICEIDX_POSTCAS_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skipped_tid_precas(bc):\n",
    "    if len(bc_tid_spliceidx_precas_map[bc]) > 1:\n",
    "        max_count = 0\n",
    "        best_tid = None\n",
    "        for tid in bc_tid_spliceidx_precas_map[bc]:\n",
    "            if tid != 'SKIPPED':\n",
    "                count = sum(bc_tid_spliceidx_precas_map[bc][tid][spliceidx] for spliceidx in bc_tid_spliceidx_precas_map[bc][tid])\n",
    "                if count > max_count:\n",
    "                    max_count = count\n",
    "                    best_tid = tid\n",
    "        if best_tid is not None:\n",
    "            best_spliceidx = max((bc_tid_spliceidx_precas_map[bc][best_tid][spliceidx] ,spliceidx) \n",
    "                                 for spliceidx in bc_tid_spliceidx_precas_map[bc][best_tid])[1]\n",
    "            return best_tid, best_spliceidx\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def get_skipped_indel_postcas(bc):\n",
    "    max_count = 0\n",
    "    best_indel1 = None\n",
    "    if len(bc_tid_spliceidx_postcas_map[bc]) > 1:\n",
    "        for tid in bc_tid_spliceidx_postcas_map[bc]:\n",
    "            if tid != 'SKIPPED':\n",
    "                for indel in bc_tid_spliceidx_postcas_map[bc][tid]:\n",
    "                    count = bc_tid_spliceidx_postcas_map[bc][tid][indel]\n",
    "                    if count > max_count:\n",
    "                        max_count = count\n",
    "                        best_indel1 = (tid, indel)\n",
    "    \n",
    "    return best_indel1\n",
    "\n",
    "\n",
    "def generate_gid_spliceidx_count_map(bc_tid_spliceidx_map, mode='precas'):\n",
    "    gid_spliceidx_count_map = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "    \n",
    "    for bc in tqdm(bc_tid_spliceidx_map):\n",
    "        for tid in bc_tid_spliceidx_map[bc]:\n",
    "            if mode == 'precas':\n",
    "                if tid == 'SKIPPED':\n",
    "                    guessed_tid, spliceidx = get_skipped_tid_precas(bc)\n",
    "                    if guessed_tid is not None:\n",
    "                        payload = (spliceidx, (exp_tid_target_map[guessed_tid], 'N'))\n",
    "                        gid_spliceidx_count_map[guessed_tid][(-1, payload)] += bc_tid_spliceidx_map[bc]['SKIPPED'][-1]\n",
    "                else:\n",
    "                    payload = (exp_tid_target_map[tid], 'N')\n",
    "                    for spliceidx in bc_tid_spliceidx_map[bc][tid]:\n",
    "                        gid_spliceidx_count_map[tid][(spliceidx, payload)] += bc_tid_spliceidx_map[bc][tid][spliceidx]\n",
    "            else:\n",
    "                if tid == 'SKIPPED':\n",
    "                    guessed_p = get_skipped_indel_postcas(bc)\n",
    "                    if guessed_p is not None:\n",
    "                        gid, indel = guessed_p # indel is actually (spliceidx, indel)\n",
    "                        gid_spliceidx_count_map[gid][(-1, indel)] += bc_tid_spliceidx_map[bc]['SKIPPED'][-1]\n",
    "                else:\n",
    "                    for payload in bc_tid_spliceidx_map[bc][tid]:\n",
    "                        spliceidx, indel = payload\n",
    "                        gid = get_gid_from_indel(indel, tid)\n",
    "                        if gid is not None:\n",
    "                            gid_spliceidx_count_map[gid][payload] += bc_tid_spliceidx_map[bc][tid][payload]\n",
    "    \n",
    "    return gid_spliceidx_count_map\n",
    "\n",
    "\n",
    "def generate_indel_splice_count_map(gid_spliceidx_count_map):\n",
    "#     {\n",
    "#     indel: {\n",
    "#         C: f, \n",
    "#         B: f,\n",
    "#         spliceidx: ,\n",
    "#         gid:\n",
    "#     }\n",
    "# }\n",
    "    indel_splice_count_map = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "    \n",
    "    for gid in gid_spliceidx_count_map:\n",
    "        # Skip cases\n",
    "        for p in gid_spliceidx_count_map[gid]:\n",
    "            if p[0] == -1:\n",
    "                spliceidx, indel = p[1]\n",
    "                indel_splice_count_map[indel]['C'] += gid_spliceidx_count_map[gid][p]\n",
    "                indel_splice_count_map[indel]['spliceidx'] = spliceidx\n",
    "                indel_splice_count_map[indel]['gid'] = gid\n",
    "        # Non skip cases\n",
    "        indels = {p[1] for p in gid_spliceidx_count_map[gid] if p[0] != -1}\n",
    "        for indel in indels:\n",
    "            max_count = 0\n",
    "            best_spliceidx = None\n",
    "            total_counts = 0\n",
    "            for p in gid_spliceidx_count_map[gid]:\n",
    "                if p[1] == indel and p[0] != -1:\n",
    "                    count = gid_spliceidx_count_map[gid][p]\n",
    "                    total_counts += count\n",
    "                    if count > max_count:\n",
    "                        max_count = count\n",
    "                        best_spliceidx = p[0]\n",
    "            indel_splice_count_map[indel]['B'] += total_counts\n",
    "            indel_splice_count_map[indel]['spliceidx'] = best_spliceidx\n",
    "            indel_splice_count_map[indel]['gid'] = gid\n",
    "    return indel_splice_count_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pickle_exists(INDEL_SPLICE_PRECAS_COUNT_MAP):\n",
    "    gid_spliceidx_precas_count_map = generate_gid_spliceidx_count_map(bc_tid_spliceidx_precas_map, 'precas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary output format\n",
    "# {\n",
    "#     indel: {\n",
    "#         C: count, \n",
    "#         B: count,\n",
    "#         spliceidx: ,\n",
    "#         gid:\n",
    "#     }\n",
    "# }\n",
    "\n",
    "if not pickle_exists(INDEL_SPLICE_PRECAS_COUNT_MAP):\n",
    "    indel_splice_precas_count_map = generate_indel_splice_count_map(gid_spliceidx_precas_count_map)\n",
    "    save_bc_seq(indel_splice_precas_count_map, INDEL_SPLICE_PRECAS_COUNT_MAP)\n",
    "else:\n",
    "    indel_splice_precas_count_map = load_bc_seq(INDEL_SPLICE_PRECAS_COUNT_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pickle_exists(INDEL_SPLICE_POSTCAS_COUNT_MAP):\n",
    "    gid_spliceidx_postcas_count_map = generate_gid_spliceidx_count_map(bc_tid_spliceidx_postcas_map, 'postcas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary output format\n",
    "# {\n",
    "#     indel: {\n",
    "#         C: count, \n",
    "#         B: count,\n",
    "#         spliceidx: ,\n",
    "#         gid:\n",
    "#     }\n",
    "# }\n",
    "\n",
    "if not pickle_exists(INDEL_SPLICE_POSTCAS_COUNT_MAP):\n",
    "    indel_splice_postcas_count_map = generate_indel_splice_count_map(gid_spliceidx_postcas_count_map)\n",
    "    save_bc_seq(indel_splice_postcas_count_map, INDEL_SPLICE_POSTCAS_COUNT_MAP)\n",
    "else:\n",
    "    indel_splice_postcas_count_map = load_bc_seq(INDEL_SPLICE_POSTCAS_COUNT_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gt_splice_count_map(indel_splice_count_map):\n",
    "    gt_splice_count_map = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "    \n",
    "    for indel, splice_count_map in indel_iterator(indel_splice_count_map):\n",
    "        gid = splice_count_map['gid']\n",
    "        grna = exp_gid_grna_map[gid]\n",
    "        design_t = exp_tid_target_map[exp_gid_tid_map[gid]]\n",
    "        g_orientation = exp_grna_gid_map[grna][1]\n",
    "        pair = (grna, design_t, g_orientation)\n",
    "        gt_splice_count_map[pair]['C'] += splice_count_map['C']\n",
    "        gt_splice_count_map[pair]['B'] += splice_count_map['B']\n",
    "        \n",
    "    return gt_splice_count_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pickle_exists(GT_SPLICE_COUNT_MAP):\n",
    "    gt_splice_count_map = generate_gt_splice_count_map(indel_splice_postcas_count_map)\n",
    "    save_bc_seq(gt_splice_count_map, GT_SPLICE_COUNT_MAP)\n",
    "else:\n",
    "    gt_splice_count_map = load_bc_seq(GT_SPLICE_COUNT_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pickle_exists(GT_PRECAS_SPLICE_COUNT_MAP):\n",
    "    gt_precas_splice_count_map = generate_gt_splice_count_map(indel_splice_precas_count_map)\n",
    "    save_bc_seq(gt_precas_splice_count_map, GT_PRECAS_SPLICE_COUNT_MAP)\n",
    "else:\n",
    "    gt_precas_splice_count_map = load_bc_seq(GT_PRECAS_SPLICE_COUNT_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Empirical Exon B Retention Frequencies ($\\Psi_R$, $\\Psi_G$, and WT $\\Psi$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Psi = \\frac{T_B + 1}{T_B + T_C + 2}$\n",
    "\n",
    "The code below shows how these values are calculated. The same calculations will happen in subsequent notebooks for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSEUDO_COUNT = 1\n",
    "\n",
    "def get_B_retention_f(indel_splice_count_map, count_thres):\n",
    "    result = []\n",
    "    gids = []\n",
    "    B_counts = []\n",
    "    C_counts = []\n",
    "    indels = []\n",
    "    total_counts = []\n",
    "    for indel, splice_count_map in indel_iterator(indel_splice_count_map):\n",
    "        if not (indel[1] == 'N' or indel[1] in DELETION_SIGNATURES or (indel[1] in INSERTION_SIGNATURES and indel[2] == 1)):\n",
    "            continue\n",
    "            \n",
    "        total = splice_count_map['C'] + splice_count_map['B']\n",
    "        if total <= count_thres:\n",
    "            continue\n",
    "            \n",
    "        C_f = (splice_count_map['C'] + PSEUDO_COUNT) / (splice_count_map['C'] + splice_count_map['B'] + 2*PSEUDO_COUNT)\n",
    "        result.append(1 - C_f)\n",
    "        total_counts.append(splice_count_map['C'] + splice_count_map['B'])\n",
    "        B_counts.append(splice_count_map['B'])\n",
    "        C_counts.append(splice_count_map['C'])\n",
    "        gids.append(splice_count_map['gid'])\n",
    "        indels.append(indel)\n",
    "    return result, gids, indels, B_counts, C_counts, total_counts\n",
    "\n",
    "\n",
    "def get_aggBf_scores(gt_splice_count_map):\n",
    "    aggBf_scores = []\n",
    "    aggBf_counts = []\n",
    "    B_counts = []\n",
    "    C_counts = []\n",
    "    gids = []\n",
    "    for gt in gt_splice_count_map.keys():\n",
    "        m = gt_splice_count_map[gt]\n",
    "        \n",
    "        gids.append(exp_grna_gid_map[gt[0]][0])\n",
    "        C_f = (m['C'] + PSEUDO_COUNT) / (m['C'] + m['B'] + 2*PSEUDO_COUNT)\n",
    "        aggBf_scores.append(1 - C_f)\n",
    "        B_counts.append(m['B'])\n",
    "        C_counts.append(m['C'])\n",
    "        aggBf_counts.append(m['C'] + m['B'])\n",
    "    return aggBf_scores, gids, B_counts, C_counts, aggBf_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Psi_R$ ($\\Psi$ from a repair genotype):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_thres = 50 # Consider only repair genotypes with at least COUNT_THRES observed transcripts for computing PSI values.\n",
    "splice_precas_Bf, _, _, _, _, _ = get_B_retention_f(indel_splice_precas_count_map, 50)\n",
    "(splice_postcas_Bf, \n",
    " splice_postcas_gids, \n",
    " splice_postcas_indels, \n",
    " splice_postcas_B, \n",
    " splice_postcas_C, \n",
    " splice_postcas_total) = get_B_retention_f(indel_splice_postcas_count_map, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Psi_G$ ($\\Psi$ from a gRNA, considering all its repair genotypes observed) and \n",
    "\n",
    "WT $\\Psi$ ($\\Psi$ from a gRNA, preCas9, so no repair genotypes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggBf_postcas_scores, postcas_gids, aggBf_postcas_B, aggBf_postcas_C, aggBf_postcas_counts = get_aggBf_scores(gt_splice_count_map)\n",
    "aggBf_precas_scores, precas_gids, aggBf_precas_B, aggBf_precas_C, aggBf_precas_counts = get_aggBf_scores(gt_precas_splice_count_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean splice transcript count per repair genotype: 246.1883577851396\n"
     ]
    }
   ],
   "source": [
    "print('Mean splice transcript count per repair genotype:', np.mean(splice_postcas_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num repair genotypes represented: 2113\n"
     ]
    }
   ],
   "source": [
    "print(\"Num repair genotypes represented:\", len(splice_postcas_Bf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num gRNAs represented: 1063\n"
     ]
    }
   ],
   "source": [
    "print(\"Num gRNAs represented:\", len(set(splice_postcas_gids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "datB_postcas_df = pd.DataFrame({\n",
    "    'gRNA ID': splice_postcas_gids,\n",
    "    'Category': ['del' if indel[1] in DELETION_SIGNATURES else 'ins' for indel in splice_postcas_indels],\n",
    "    'Genotype position': [indel[3] if indel[1] in DELETION_SIGNATURES else None for indel in splice_postcas_indels],\n",
    "    'Inserted Bases': [indel[3] if indel[1] in INSERTION_SIGNATURES else None for indel in splice_postcas_indels],\n",
    "    'Length': [indel[2] if indel[1] in DELETION_SIGNATURES else 1 for indel in splice_postcas_indels],\n",
    "    'Exon B Retained Count': splice_postcas_B,\n",
    "    'Exon B Skipped Count': splice_postcas_C\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gRNA ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Genotype position</th>\n",
       "      <th>Inserted Bases</th>\n",
       "      <th>Length</th>\n",
       "      <th>Exon B Retained Count</th>\n",
       "      <th>Exon B Skipped Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5902</td>\n",
       "      <td>del</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>128.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5902</td>\n",
       "      <td>del</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>144.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3586</td>\n",
       "      <td>del</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>41.0</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5839</td>\n",
       "      <td>del</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>50.5</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119</td>\n",
       "      <td>del</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>322.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gRNA ID Category  Genotype position Inserted Bases  Length  \\\n",
       "0     5902      del                2.0           None       2   \n",
       "1     5902      del                1.0           None       1   \n",
       "2     3586      del                2.0           None       3   \n",
       "3     5839      del                3.0           None       8   \n",
       "4      119      del                0.0           None       1   \n",
       "\n",
       "   Exon B Retained Count  Exon B Skipped Count  \n",
       "0                  128.5                   0.0  \n",
       "1                  144.0                   2.0  \n",
       "2                   41.0                  10.5  \n",
       "3                   50.5                  11.0  \n",
       "4                  322.5                   3.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datB_postcas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2113"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datB_postcas_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1063"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datB_postcas_df['gRNA ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "datB_postcas_df.to_csv(os.path.join(TABLES_DIR, 'datB_postCas_table.csv.gz'), index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reads: 520196.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Reads:\", datB_postcas_df['Exon B Retained Count'].sum() + datB_postcas_df['Exon B Skipped Count'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S4 Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "datB_precas_df = pd.DataFrame({\n",
    "    'gRNA ID': precas_gids,\n",
    "    'Exon B Retained Count': aggBf_precas_B,\n",
    "    'Exon B Skipped Count': aggBf_precas_C\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gRNA ID</th>\n",
       "      <th>Exon B Retained Count</th>\n",
       "      <th>Exon B Skipped Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5902</td>\n",
       "      <td>7940</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1447</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1335</td>\n",
       "      <td>943</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1126</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3586</td>\n",
       "      <td>890</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gRNA ID  Exon B Retained Count  Exon B Skipped Count\n",
       "0     5902                   7940                   105\n",
       "1     1447                      3                     1\n",
       "2     1335                    943                    33\n",
       "3     1126                     13                     3\n",
       "4     3586                    890                    30"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datB_precas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1697"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datB_precas_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Num Targets represented:', 1697)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Num Targets represented:\", len(set(exp_gid_tid_map[g] for g in datB_precas_df['gRNA ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S3 Fig) Number of gRNAs in both PostCas9 and PreCas9 (WT) datasets:\n",
      "735\n"
     ]
    }
   ],
   "source": [
    "print(\"(S3 Fig) Number of gRNAs in both PostCas9 and PreCas9 (WT) datasets:\")\n",
    "print(len(set(splice_postcas_gids) & set(precas_gids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "datB_precas_df.to_csv(os.path.join(TABLES_DIR, 'datB_preCas_table.csv.gz'), index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reads: 3443915\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Reads:\", datB_precas_df['Exon B Retained Count'].sum() + datB_precas_df['Exon B Skipped Count'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:skipguide_data_processing] *",
   "language": "python",
   "name": "conda-env-skipguide_data_processing-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
